{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network(deep learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:28:28.726214Z",
     "start_time": "2023-01-05T04:28:28.601222Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network(인공신경망)\n",
    "> **Neural network**는 사람의 신경을 본따 만든 머신러닝 알고리즘이다.  \n",
    "종속변수가 있어야 하는 **지도학습** 모델이며 출력 구분에 따라 **예측/분류 문제에 모두 사용**이 가능하다.  \n",
    "기존 선형회귀/로지스틱회귀 뿐 아니라 훨씬 더 복잡한 다차원의 비선형성 모델까지 표현이 가능하다.  \n",
    ">> `DNN`, `RNN`, `CNN`, `LSTM`을 기본으로 한 수 많은 네트워크 구조가 지속적으로 연구되고 있다.  \n",
    "이미지 처리에 `CNN`, 자연어 처리에 `LSTM`을 기본구조로 많이 사용  \n",
    "최근에는 데이터에 따른 기본구조를 따르지 않고 모델 전환에 관한 연구가 진행되고 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본적인 구조\n",
    ">기본적인 신경망의 layer 단위로 구성이 되는데 기본적인 구조는 아래와 같다.  \n",
    ">> **input layer** : **설명변수(X)**를 받아들이는(저장)하는 레이어  \n",
    "**hidden layer** : 연산 layer, **input과 output layer를 제외 한 모든 layer**는 hidden layer이다.  \n",
    "**output layer** : 출력 layer, 목적식 혹은 **예측/분류에 따라 출력 layer를 다르게** 설정하여 모델링.  \n",
    "**node** : layer에 포함 된 동그라미 하나  \n",
    "**weight(가중치)** : node 와 node간 연결되어 있는 회색 화살표  \n",
    "<img src=\"https://drive.google.com/uc?id=1qjjXfWEPnVVnD_rwqHsq8enC9Vgzyggm\">\n",
    "\n",
    "#### 선형결합 함수\n",
    "# $$ z = w^Tx + b $$\n",
    "> hidden layer에 도달하는 값은 결국 X와 w의 선형 함수식으로 나타낼 수 있으며 벡터/매트릭스 연산으로 계산한다.  \n",
    ">><img src=\"https://drive.google.com/uc?id=1NRXuxc1qx_EwIZ9A63_JAkKD6uSpivHb\">\n",
    "\n",
    "\n",
    "#### perceptron(퍼셉트론)\n",
    "# $$ \\hat{y} = g(\\sum_{i=1}^m x_iw_i)$$\n",
    "> 인공신경망의 가장 기본이 되는 단위.  \n",
    "위의 기본적인 신경망 구조에서 hidden layer의 노드 하나에 대한 자세한 구조를 살펴본다면 아래와 같은 구조를 갖는다.  \n",
    "각 노드의 선형 함수의 합에 비선형 **활성함수 g(activation function)를 적용**하여 비선형 변환을 만든다.  \n",
    ">><img src=\"https://drive.google.com/uc?id=1-KcMMdqfEHYwPeDuGQQ5623VAvp7oxXm\">\n",
    "\n",
    "#### activation function(활성화함수)\n",
    "> 노드의 선형식 결과를 비선형 출력결과로 만들어주는 함수  \n",
    "딥러닝 강의가 아니기에 각 함수별 특징은 참고링크를 확인해주세요  \n",
    "https://deepinsight.tistory.com/113\n",
    ">><img src=\"https://drive.google.com/uc?id=1G95TtpGcYZ75-P4tjSX3EzpP6hfi5loO\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "### Cost functions\n",
    "> 일반적인 머신러닝 모델과 마찬가지로 **비용함수(cost function)를 정의하고 최소화 하는 방향**으로 학습시킨다.  \n",
    "\n",
    "모델 출력값에 따른 비용함수는 아래와 같다.\n",
    "\n",
    "> **MAE**(회귀모델)\n",
    ">><img src=\"https://drive.google.com/uc?id=1RnkdTrErpOEK_pqPgrJASSpaYZMaQtII\">\n",
    "\n",
    "> **Cross entropy loss**(이진 분류)\n",
    ">><img src=\"https://drive.google.com/uc?id=1cWDiTXKPaKPMSmZ2wpPyhtUEcZml3k4i\">\n",
    "\n",
    "> **Softmax**(다중 클래스 분류)\n",
    ">><img src=\"https://drive.google.com/uc?id=1oNzYAkccbohXOEEK3gifvWP_H69AZOAs\">\n",
    "\n",
    "### 최적화(순전파)\n",
    "> 결국 cost function이 의미하고자 하는 바는 **비용함수를 최소화 시키는 가중치를 찾고싶다** 이다.\n",
    ">><img src=\"https://drive.google.com/uc?id=1vpAbQJAhkYKUG6sNmb3CgvtBdY4vyten\">\n",
    "<img src=\"https://drive.google.com/uc?id=1ImhFj4qtiYazwUb7YLjAqo38g2HHjyLO\">\n",
    "\n",
    "일반적인 머신러닝 알고리즘이 가정에 따른 비용함수 최소화를 목적으로 했다면 신경망의 최적화는 **가중치에 따른 비용함수 최소화**를 목적으로 한다.  \n",
    "즉, 학습이 진행되는 스텝마다 가중치를(그래디언트 반대방향으로)업데이트 하면서 최적값을 찾는 과정을 거친다.\n",
    "\n",
    "### 역전파(back propagation)\n",
    "> 오차에 대한 가중치를 업데이트 하기 위한 방법론으로 가중치의 변화가 최종 비용함수에 어떤 영향을 미치는지를 계산  \n",
    "chain rule을 활용 비용함수로부터 역방향으로 계산한다.\n",
    ">> w2에 대한 가중치 업데이트\n",
    "<img src=\"https://drive.google.com/uc?id=1NqlnOVAJCCDeWnk9r_5AK1x_b6Y_R62A\">\n",
    ">> w2에 대한 비용함수의 편미분 식을 ($\\hat{y}$에 대한 비용함수 편미분) X (w2에 대한 $\\hat{y}$ 편미분)의 식으로 전개\n",
    "<img src=\"https://drive.google.com/uc?id=1hOIW7EXow5gQab68QOo5HII2JAzhDg0u\">\n",
    ">> 이후 w1에 대한 가중치 업데이트도 마찬가지 방법으로 편미분 chain rule 활용한다.\n",
    "<img src=\"https://drive.google.com/uc?id=1WmhbYLibGLvxuxdLAKKREnkC9zkuedff\">\n",
    ">><img src=\"https://drive.google.com/uc?id=1itEcg3mgJWvdH0n7odwHBRbm3ieg6cB_\">\n",
    "\n",
    "### 학습률(learning rate)\n",
    "> 신경망 학습에는 학습률이 중요한데 chain rule을 통해 구해지는 업데이트 값에 학습률을 곱해 가중치를 업데이트 한다.  \n",
    "적절한 학습률은 너무 큰 업데이트값을 사용함으로서 모델 학습이 되지 않거나 너무 작은 업데이트 값을 곱해 학습이 더뎌지는 문제를 해결할 수 있다.  \n",
    "가중치 X 학습률 $\\eta$ 만큼 업데이트 하면서 최적값을 찾는 과정을 거친다.\n",
    "# $$W \\leftarrow W - \\eta{{\\partial j}(W)\\over{\\partial W}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## neural network 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:25:11.612387Z",
     "start_time": "2023-01-05T04:25:11.588210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  \\\n",
       "0           0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0   \n",
       "1           1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0   \n",
       "2           2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0   \n",
       "3           3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0   \n",
       "4           4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0   \n",
       "\n",
       "     TAX  PTRATIO       B  LSTAT     y  \n",
       "0  296.0     15.3  396.90   4.98  24.0  \n",
       "1  242.0     17.8  396.90   9.14  21.6  \n",
       "2  242.0     17.8  392.83   4.03  34.7  \n",
       "3  222.0     18.7  394.63   2.94  33.4  \n",
       "4  222.0     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kospi 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:26:02.690727Z",
     "start_time": "2023-01-05T04:26:02.674511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        2\n",
       "3        3\n",
       "4        4\n",
       "      ... \n",
       "501    501\n",
       "502    502\n",
       "503    503\n",
       "504    504\n",
       "505    505\n",
       "Name: Unnamed: 0, Length: 506, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불필요한 데이터 삭제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:26:06.429877Z",
     "start_time": "2023-01-05T04:26:06.422978Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:26:06.582509Z",
     "start_time": "2023-01-05T04:26:06.578362Z"
    }
   },
   "outputs": [],
   "source": [
    "# 테스트 데이터 분할\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:26:06.757097Z",
     "start_time": "2023-01-05T04:26:06.755070Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:26:06.947548Z",
     "start_time": "2023-01-05T04:26:06.942918Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nhidden_layer_sizes=(39,) : 히든레이어 구조(40, 40, 60) 튜플로 전달\\nactivation='relu': 활성함수\\nlearning_rate_init=0.001: 학습률\\nmax_iter=200 : 학습 반복 횟수\\n\\n데이터에 맞는 히든레이어 구조는 다 다릅니다. \\n큰 데이터라도 깊이가 얕은 모델의 성능이 좋을 수 있어 파라메터 서칭이 필요합니다.\\n일반적으로는 구조가 복잡해질수록 학습률을 줄이면서 반복횟수를 많이 가져가게 됩니다.\\n\\n이 외 파라메터는 최적화 관련 파라메터인데 현재 가장 좋은 알고리즘이 기본적으로 탑재되어 있으니 그냥 쓰시면 됩니다.\\n수업시간에 모두 다루기 어렵습니다.\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성\n",
    "\n",
    "'''\n",
    "hidden_layer_sizes=(39,) : 히든레이어 구조(40, 40, 60) 튜플로 전달\n",
    "activation='relu': 활성함수\n",
    "learning_rate_init=0.001: 학습률\n",
    "max_iter=200 : 학습 반복 횟수\n",
    "\n",
    "데이터에 맞는 히든레이어 구조는 다 다릅니다. \n",
    "큰 데이터라도 깊이가 얕은 모델의 성능이 좋을 수 있어 파라메터 서칭이 필요합니다.\n",
    "일반적으로는 구조가 복잡해질수록 학습률을 줄이면서 반복횟수를 많이 가져가게 됩니다.\n",
    "\n",
    "이 외 파라메터는 최적화 관련 파라메터인데 현재 가장 좋은 알고리즘이 기본적으로 탑재되어 있으니 그냥 쓰시면 됩니다.\n",
    "수업시간에 모두 다루기 어렵습니다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:26:07.859602Z",
     "start_time": "2023-01-05T04:26:07.525872Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byun/miniforge3/envs/main/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(40, 40, 60))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(hidden_layer_sizes=(40, 40, 60))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(40, 40, 60))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:26:08.024895Z",
     "start_time": "2023-01-05T04:26:08.016413Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 예측 결과값 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T04:26:09.477694Z",
     "start_time": "2023-01-05T04:26:09.462102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score :0.7207748398384975\n",
      "RMSE :4.4219159198837\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
